{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UjNUTa3OHEB"
      },
      "source": [
        "# Mask RCNN - Performing Instance Segementation for Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uwN0NHo5NPIP",
        "outputId": "f94a54cc-fa73-4861-a654-72e674320183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 176MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MaskRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
              "    )\n",
              "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
              "    (mask_head): MaskRCNNHeads(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Conv2dNormActivation(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (mask_predictor): MaskRCNNPredictor(\n",
              "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing Required Dependencies\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "# Load the Working Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Import MRCNN Model\n",
        "mask_rcnn = torchvision.models.detection.maskrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "mask_rcnn.eval().to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dGs03lSGI4IF"
      },
      "outputs": [],
      "source": [
        "# COCO Dateset for Class Labels\n",
        "# These are the classes that are available in the COCO-Dataset\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "# Create a color map for each COCO class\n",
        "COCO_COLORS = {\n",
        "    idx: tuple([random.randint(0, 255) for _ in range(3)])      # Key\n",
        "    for idx in range(len(COCO_INSTANCE_CATEGORY_NAMES))         # Value\n",
        "}\n",
        "\n",
        "def color_for_label(label_idx):\n",
        "    return COCO_COLORS.get(label_idx, (255, 255, 255))  # Returns the color of each idx associated, else white\n",
        "\n",
        "def apply_color_mask(img_rgb, mask, color, alpha=0.5):\n",
        "    # Outputs the blended Image with opacity factor alpha\n",
        "    # alpha = 0 (no mask, fully transparent)\n",
        "    out = img_rgb.copy()\n",
        "    colored = np.zeros_like(out, dtype=np.uint8)\n",
        "    colored[mask == 1] = color\n",
        "    return cv2.addWeighted(out, 1, colored, alpha, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "npoEupsAC1CH"
      },
      "outputs": [],
      "source": [
        "CLASS_IDS = list(range(1, 81))  # All COCO classes\n",
        "CONF_THRESHOLD = 0.5 # @param {\"type\":\"number\",\"placeholder\":\"Enter Minimum Confidence Threshold\"}\n",
        "MASK_THRES = 0.5 # @param {\"type\":\"number\",\"placeholder\":\"Enter Minimum Mask Threshold\"}\n",
        "max_long_side = 1280 # @param {\"type\":\"integer\",\"placeholder\":\"Enter Max Long Side\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l2uGPU7Ngzg3"
      },
      "outputs": [],
      "source": [
        "# Making Directories to Store Input and Output Data\n",
        "video_dir_input = 'video_dir_input'           # Storing Input Video\n",
        "os.makedirs(video_dir_input,exist_ok=True)\n",
        "\n",
        "video_dir_output = 'video_dir_output'         # Storing Output Video\n",
        "os.makedirs(video_dir_output,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jjmnpr_Litus"
      },
      "outputs": [],
      "source": [
        "INPUT_VIDEO = os.path.join(video_dir_input,'NightLife2.mp4')\n",
        "OUTPUT_VIDEO = os.path.join(video_dir_output,'NightLife2_output.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZlyV_nQqSoWq"
      },
      "outputs": [],
      "source": [
        "# Utilities\n",
        "def letterbox_resize(image,max_long_side=640):\n",
        "  if max_long_side is None:\n",
        "    return Image,1.0\n",
        "  h,w = image.shape[:2]\n",
        "  long_side = max(h,w)\n",
        "  if long_side <= max_long_side:\n",
        "    return image,1.0\n",
        "  scale = max_long_side/float(long_side)\n",
        "  new_h,new_w = int(round(scale * h)),int(round(scale * w))\n",
        "  image = cv2.resize(image,(new_w,new_h),interpolation=cv2.INTER_AREA) # cv2 Documentation Requires Width x Heigh\n",
        "  return image,scale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M97YgrU7VBFe"
      },
      "outputs": [],
      "source": [
        "# Helper Function to Read, and Write the Video Output\n",
        "def video_readwrite(path_in,path_out,max_long_side):\n",
        "  assert os.path.isfile(path_in), f\"Cannot find input video at {path_in}\"\n",
        "  cap = cv2.VideoCapture(path_in)\n",
        "  assert cap.isOpened(), \"Failed to open input file.\"\n",
        "\n",
        "  src_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  src_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  if fps is None or fps <=0 or math.isnan(fps):\n",
        "    fps = 25.0\n",
        "\n",
        "  dummy = np.zeros((src_h,src_w,3),dtype=np.uint8)\n",
        "  temp,_ = letterbox_resize(dummy,max_long_side)\n",
        "  dst_h,dst_w = temp.shape[0],temp.shape[1]\n",
        "\n",
        "  # Creating the Output\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "  out = cv2.VideoWriter(path_out,fourcc,fps,(dst_w,dst_h))\n",
        "  assert out.isOpened(), \"Failed to output writer\"\n",
        "\n",
        "  return cap,out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8rMf8KpxeC8i"
      },
      "outputs": [],
      "source": [
        "# Pre-processing the Input Frames to convert to Tensor\n",
        "# NOTE: Aviod Normalization in pre-processing as the ResNet Model Already performs the Normalization\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwupb-WXTPoa",
        "outputId": "a85dd255-5029-4b55-9e8b-1211d01af0c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Total Frames: 532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1782916257.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed: 50/532\n",
            "Processed: 100/532\n",
            "Processed: 150/532\n",
            "Processed: 200/532\n",
            "Processed: 250/532\n",
            "Processed: 300/532\n",
            "Processed: 350/532\n",
            "Processed: 400/532\n",
            "Processed: 450/532\n",
            "Processed: 500/532\n",
            "Can't receive frame (stream end?). Exiting ...\n",
            "Done. Saved to: video_dir_output/NightLife2_output.mp4\n",
            "Processing speed: 1.52 FPS\n"
          ]
        }
      ],
      "source": [
        "cap, out = video_readwrite(INPUT_VIDEO, OUTPUT_VIDEO, max_long_side)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT) > 0 else None\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Total Frames: {total_frames}\")\n",
        "\n",
        "processed, t0 = 0, time.time()\n",
        "\n",
        "# Main processing loop with inference mode for efficiency\n",
        "with torch.inference_mode():\n",
        "    while True:\n",
        "        # Read frame from video\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
        "            break\n",
        "\n",
        "        # Preprocess frame\n",
        "        # Resize frame while maintaining aspect ratio with letterboxing\n",
        "        # NOTE: Default Color Code of CV2 is BGR\n",
        "        frame_bgr, _ = letterbox_resize(frame, max_long_side=max_long_side)\n",
        "        H, W = frame_bgr.shape[:2]  # Get the first 2 dimensions\n",
        "\n",
        "        # Scale thickness and font based only on frame *height*\n",
        "        base = H / 640.0   # relative scale; 640px height as reference\n",
        "        box_th   = max(1, int(round(2 * base)))   # usually 1–3\n",
        "        font_sc  = 0.5 * base                     # readable but not oversized\n",
        "        text_th  = max(1, int(round(1 * base)))   # text stroke thickness\n",
        "\n",
        "        # Convert BGR to RGB for model input\n",
        "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Apply preprocessing transforms (normalization, tensor conversion)\n",
        "        inp = preprocess(Image.fromarray(frame_rgb)).to(device)\n",
        "\n",
        "        # Model inference\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            outputs = mask_rcnn([inp])[0]  # Get first (and only) batch item\n",
        "\n",
        "        # Extract model outputs\n",
        "        boxes = outputs['boxes'].detach().cpu().numpy()              # Bounding boxes [N, 4]\n",
        "        labels = outputs['labels'].detach().cpu().numpy()            # Class labels [N]\n",
        "        scores = outputs['scores'].detach().cpu().numpy()            # Confidence scores [N]\n",
        "        raw_masks = outputs['masks'].detach().cpu().numpy()          # Segmentation masks [N,1, H, W]\n",
        "        masks = (raw_masks[:,0] > MASK_THRES).astype(np.uint8)       # [N,H,W] 0/1 Binary\n",
        "\n",
        "        out_img = frame_rgb.copy()      # Draw on this\n",
        "\n",
        "        # Process each detected objects\n",
        "        for i in range(len(boxes)):\n",
        "            if float(scores[i]) < CONF_THRESHOLD:\n",
        "                continue\n",
        "\n",
        "            # Map Index to Label\n",
        "            label_idx = int(labels[i])\n",
        "            pred_name = COCO_INSTANCE_CATEGORY_NAMES[label_idx]\n",
        "\n",
        "            # Resize mask to match frame dimensions if needed\n",
        "            masks_i = masks[i]\n",
        "            if masks_i.shape[:2] != (H, W):\n",
        "                masks_i = cv2.resize(masks_i, (W, H), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            # Get fixed color for the class\n",
        "            color = color_for_label(label_idx)\n",
        "            blended_img = apply_color_mask(out_img, masks_i, color, alpha=0.5)\n",
        "\n",
        "            # Draw Bounding Box\n",
        "            x1,y1,x2,y2 = boxes[i].astype(int)\n",
        "            #x1,y1 = max(0,x1),max(0,y1)\n",
        "            #x2,y2 = max(W -1,x2),max(H -1,y2)\n",
        "            box_color = (0,255,0) # Green for added Visibility\n",
        "            cv2.rectangle(blended_img,(x1,y1),(x2,y2),box_color,thickness=box_th)\n",
        "\n",
        "            # Draw Text\n",
        "            label_text = f\"{pred_name}: {scores[i]:.2f}\"\n",
        "            cv2.putText(\n",
        "                blended_img,\n",
        "                label_text,\n",
        "                (x1,max(15, y1 - 5)),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                font_sc,\n",
        "                (0,255,0),\n",
        "                thickness=text_th\n",
        "            )\n",
        "\n",
        "            out_img = blended_img\n",
        "\n",
        "        # Convert back to BGR for Writer to write\n",
        "        out_frame = cv2.cvtColor(out_img,cv2.COLOR_RGB2BGR)\n",
        "        out.write(out_frame)\n",
        "        processed += 1\n",
        "\n",
        "        # Step 2j: Progress reporting\n",
        "        if processed % 50 == 0 and total_frames:\n",
        "                print(f\"Processed: {processed}/{total_frames}\")\n",
        "\n",
        "# Step 3: Cleanup and final stats\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "dt = time.time() - t0\n",
        "fps_eff = processed / dt if dt > 0 else 0.0\n",
        "print(f\"Done. Saved to: {OUTPUT_VIDEO}\")\n",
        "print(f\"Processing speed: {fps_eff:.2f} FPS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtsPFX6aj32i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
